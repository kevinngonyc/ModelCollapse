{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfcc712-9631-42c7-bdc4-932c7fb8a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/ngok02/ModelCollapse/vae\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "_, current_folder_name = os.path.split(os.getcwd())\n",
    "if current_folder_name == \"notebooks\":\n",
    "    os.chdir(\"..\")  \n",
    "print(os.getcwd())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51870f99-114a-4a87-8650-7337993ebc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6297fcb-1dfc-4931-aa69-ca1c4e8e90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = 20\n",
    "batch_size = 256\n",
    "capacity = 64\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c283232b-1af7-4298-b289-a0082c7492c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='../data', train = True, download = True, transform = ToTensor())\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='../data', train = False, download = True, transform = ToTensor())\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257a2809-9ff8-4025-8e74-ddf4ed9ef81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1be3eb5-d870-4db3-9e58-5c9243021c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        c = capacity\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
    "        self.fc1 = nn.Linear(in_features=c*2*7*7, out_features=latent_dims)\n",
    "        self.fc2 = nn.Linear(in_features=latent_dims, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5b7eac5-f91e-4900-a45f-8633047a1e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch [1 / 30] average cross entropy error: 1.700136\n",
      "Epoch [2 / 30] average cross entropy error: 1.591612\n",
      "Epoch [3 / 30] average cross entropy error: 1.578432\n",
      "Epoch [4 / 30] average cross entropy error: 1.574034\n",
      "Epoch [5 / 30] average cross entropy error: 1.570537\n",
      "Epoch [6 / 30] average cross entropy error: 1.568301\n",
      "Epoch [7 / 30] average cross entropy error: 1.528654\n",
      "Epoch [8 / 30] average cross entropy error: 1.478766\n",
      "Epoch [9 / 30] average cross entropy error: 1.474834\n",
      "Epoch [10 / 30] average cross entropy error: 1.472910\n",
      "Epoch [11 / 30] average cross entropy error: 1.471807\n",
      "Epoch [12 / 30] average cross entropy error: 1.470991\n",
      "Epoch [13 / 30] average cross entropy error: 1.470055\n",
      "Epoch [14 / 30] average cross entropy error: 1.469671\n",
      "Epoch [15 / 30] average cross entropy error: 1.469444\n",
      "Epoch [16 / 30] average cross entropy error: 1.468882\n",
      "Epoch [17 / 30] average cross entropy error: 1.468390\n",
      "Epoch [18 / 30] average cross entropy error: 1.467627\n",
      "Epoch [19 / 30] average cross entropy error: 1.467379\n",
      "Epoch [20 / 30] average cross entropy error: 1.466953\n",
      "Epoch [21 / 30] average cross entropy error: 1.466117\n",
      "Epoch [22 / 30] average cross entropy error: 1.466114\n",
      "Epoch [23 / 30] average cross entropy error: 1.466531\n",
      "Epoch [24 / 30] average cross entropy error: 1.466906\n",
      "Epoch [25 / 30] average cross entropy error: 1.466337\n",
      "Epoch [26 / 30] average cross entropy error: 1.466042\n",
      "Epoch [27 / 30] average cross entropy error: 1.466022\n",
      "Epoch [28 / 30] average cross entropy error: 1.465916\n",
      "Epoch [29 / 30] average cross entropy error: 1.465746\n",
      "Epoch [30 / 30] average cross entropy error: 1.465639\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier()\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=classifier.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "classifier.train()\n",
    "\n",
    "train_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for image_batch, y in train_dataloader:\n",
    "        image_batch = image_batch.to(device)\n",
    "        target = F.one_hot(y, num_classes=10).float().to(device)\n",
    "        \n",
    "        pred = classifier(image_batch)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_avg[-1] += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    print('Epoch [%d / %d] average cross entropy error: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ceb83a1-a069-42b5-83b5-32b765b05af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "accuracy = 0\n",
    "num_samples = 0\n",
    "for image_batch, y in test_dataloader:\n",
    "    image_batch = image_batch.to(device)\n",
    "    target = y.to(device)\n",
    "    \n",
    "    pred = torch.argmax(classifier(image_batch), dim=1)\n",
    "    accuracy += torch.sum(pred == target).item()\n",
    "    num_samples += len(image_batch)\n",
    "\n",
    "print(f\"Accuracy: {accuracy / num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c23d4-eaea-4394-b8b4-66fac3979a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
